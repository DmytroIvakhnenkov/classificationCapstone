{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import feature, color, util, io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract image features and image labels to x and y tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "path = '../weatherconditiondataset/'\n",
    "n = 1125\n",
    "n_bins = 10\n",
    "x = torch.zeros((n, n_bins))  # features\n",
    "y = [] # labels\n",
    "for i, f in enumerate(os.listdir(path)):\n",
    "    # FEATURES\n",
    "    img = io.imread(path+f)\n",
    "    # Convert image to grayscale\n",
    "    if (img.ndim == 3 and img[0, 0, :].size == 3):\n",
    "        img_gray = color.rgb2gray(img)\n",
    "    elif(img.ndim == 3 and img[0, 0, :].size == 4):\n",
    "        img_gray = color.rgb2gray(img[:, :, :3])\n",
    "    else:\n",
    "        img_gray = img\n",
    "    \n",
    "    # Convert the image to an unsigned 8-bit integer type\n",
    "    discretized_image = util.img_as_ubyte(img_gray)\n",
    "    # Extract LBP features\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    lbp = feature.local_binary_pattern(discretized_image, n_points, radius, method='uniform')\n",
    "    # Create histogram of LBP codes\n",
    "    n_bins = 10\n",
    "    hist, bins = np.histogram(lbp, bins=n_bins, range=(0, n_bins), density=True)\n",
    "    x[i] = torch.tensor(hist)\n",
    "    # LABELS\n",
    "    string = \"\"\n",
    "    i = 0\n",
    "    while(ord(f[i]) > 57):\n",
    "        string += f[i]\n",
    "        i = i + 1\n",
    "    y.append(string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get information on labels, transform them from string to one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "classNames = set(y)\n",
    "classCount = {}\n",
    "classNumber = {}\n",
    "numbClasses = len(classNames)\n",
    "\n",
    "for i, c in enumerate(classNames): \n",
    "    classNumber[c] =  i\n",
    "for c in y: \n",
    "    classCount[c] =  classCount.get(c, 0) + 1\n",
    "\n",
    "y_OneHot = torch.zeros((n, numbClasses))  # features\n",
    "\n",
    "for i, c in enumerate(y):\n",
    "    numb = torch.tensor(classNumber[c])\n",
    "    y_OneHot[i] = one_hot(numb, num_classes = numbClasses).float()\n",
    "\n",
    "print(classCount)\n",
    "print(classNumber)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showcase the LBP histograms for different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "classMeanHist = torch.zeros(len(classNames), n_bins)\n",
    "\n",
    "for hist, label in zip(x,y):\n",
    "    classMeanHist[classNumber[label]] = classMeanHist[classNumber[label]] + hist\n",
    "\n",
    "for c in classNames:\n",
    "    classMeanHist[classNumber[c]] = classMeanHist[classNumber[c]] / classCount[c]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(8, 4))\n",
    "# Display each image in a different subplot\n",
    "for i, c in enumerate(classNames):\n",
    "    axes[i].bar(bins[0:10], classMeanHist[classNumber[c]])\n",
    "    axes[i].set_title(c + \" image\")\n",
    "\n",
    "plt.xticks(bins[0:10], [int(bin) for bin in bins[0:10]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1:\n",
      "Fold #2:\n",
      "Fold #3:\n",
      "Fold #4:\n",
      "Fold #5:\n",
      "Average test accuracy: 41.46%\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/media/commlab/TenTB/home/dmytro/AI_HW#1/')\n",
    "%run ../heatmap.py\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# create a KFold object\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# shuffle the data and split it in two\n",
    "shuffled_indices = np.random.permutation(len(x))\n",
    "x = x[shuffled_indices]\n",
    "y_OneHot = y_OneHot[shuffled_indices]\n",
    "\n",
    "x = x[:round(n/2), :]\n",
    "y_OneHot = y_OneHot[:round(n/2), :]\n",
    "\n",
    "k = 5  # number of folds\n",
    "neighborN = 100 # Choose the value of k\n",
    "\n",
    "cm_total = np.zeros((4, 4))\n",
    "avg_test_acc = 0\n",
    "\n",
    "# create a KFold object\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# loop over the folds\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print(\"Fold #\" + str(i) + \":\")\n",
    "\n",
    "    # split the data into training and test sets\n",
    "    x_train, y_train = x[train_index], y_OneHot[train_index]\n",
    "    x_test, y_test = x[test_index], y_OneHot[test_index]\n",
    "\n",
    "    # Create a kNN classifier object\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighborN)\n",
    "\n",
    "    # Train the classifier on your data\n",
    "    knn.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(x_test)\n",
    "\n",
    "    # Get the index of an array element with the highest probability\n",
    "    y_pred = np.argmax(y_pred, axis = 1)\n",
    "    y_test = np.argmax(y_test, axis = 1)\n",
    "    # Count correct predictions\n",
    "    y_test = y_test.detach().cpu().numpy()\n",
    "    test_acc = np.equal(y_pred, y_test).sum()/y_pred.size\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred, labels = [0, 1, 2, 3])\n",
    "\n",
    "    avg_test_acc += test_acc\n",
    "    cm_total = cm_total + cm\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "print(\"Average test accuracy:\", str(round(avg_test_acc/k*100, 2)) + \"%\")\n",
    "grid_labels = ['cloudy', 'sunrise', 'shine', 'rain']\n",
    "# compute the sum of each row\n",
    "row_sums = cm_total.sum(axis=1)\n",
    "cm_normalized = cm_total / row_sums[:, np.newaxis]\n",
    "im, cbar = heatmap(cm_normalized, grid_labels, grid_labels)\n",
    "annotate_heatmap(im)\n",
    "plt.savefig(\"confusionMatrix_k_100_half_data.png\")\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full data <br>\n",
    "k = 3: Average test accuracy: 57.16% <br>\n",
    "k = 5: Average test accuracy: 60.36% <br>\n",
    "k = 10: Average test accuracy: 57.07% <br>\n",
    "k = 20: Average test accuracy: 56.98% <br>\n",
    "k = 100: Average test accuracy: 49.16% <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half data <br>\n",
    "k = 3: Average test accuracy: 57.14% <br>\n",
    "k = 5: Average test accuracy: 59.43% <br>\n",
    "k = 10: Average test accuracy: 57.28% <br>\n",
    "k = 20: Average test accuracy: 55.52% <br>\n",
    "k = 100: Average test accuracy: 41.65% <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GPU(s) are available!\n",
      "GPU 0: NVIDIA GeForce RTX 2080 Ti\n",
      "\tCompute capability: (7, 5)\n",
      "\tMemory: 11019.56 MB\n",
      "GPU 1: NVIDIA GeForce RTX 2080 Ti\n",
      "\tCompute capability: (7, 5)\n",
      "\tMemory: 11018.25 MB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f'{torch.cuda.device_count()} GPU(s) are available!')\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f'GPU {i}: {torch.cuda.get_device_name(i)}')\n",
    "        print(f'\\tCompute capability: {torch.cuda.get_device_capability(i)}')\n",
    "        print(f'\\tMemory: {torch.cuda.get_device_properties(i).total_memory / 1024 ** 2:.2f} MB')\n",
    "else:\n",
    "    print('CUDA is not available.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
